{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d308a0",
   "metadata": {},
   "source": [
    "### THU THẬP DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b825c42",
   "metadata": {},
   "source": [
    "***Thêm thư viện cần thiết***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59759313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b6c32",
   "metadata": {},
   "source": [
    "***Tạo thư mục làm việc của Scrapy*** (sau đó di chuyển vào thư mục làm việc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy startproject air_quality #Tạo thư mục làm việc air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd air_quality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b128ed",
   "metadata": {},
   "source": [
    "***Bắt đầu thu thập dữ liệu***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ff645",
   "metadata": {},
   "source": [
    "class AirQualityItem dùng để chứa các spider field cần thiết để chuyền sang file json khi crawl dữ liệu về"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirQualityItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    Rank = scrapy.Field()\n",
    "    City = scrapy.Field()\n",
    "    Year_2021 = scrapy.Field()\n",
    "    Jan = scrapy.Field()\n",
    "    Feb = scrapy.Field()\n",
    "    Mar = scrapy.Field()\n",
    "    Apr = scrapy.Field()\n",
    "    May = scrapy.Field()\n",
    "    Jun = scrapy.Field()\n",
    "    Jul = scrapy.Field()\n",
    "    Aug = scrapy.Field()\n",
    "    Sep = scrapy.Field()\n",
    "    Oct = scrapy.Field()\n",
    "    Nov = scrapy.Field()\n",
    "    Dec = scrapy.Field()\n",
    "    Year_2020 = scrapy.Field()\n",
    "    Year_2019 = scrapy.Field()\n",
    "    Year_2018 = scrapy.Field()\n",
    "    Year_2017 = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bf333",
   "metadata": {},
   "source": [
    "class collect_air_data dùng để crawl dữ liệu về và lưu vào từng spider.Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class collect_air_data(scrapy.Spider): #Khởi tạo class dùng để thu thập\n",
    "    name = 'air_datas' #Tên spider\n",
    "    \n",
    "    data = AirQualityItem() #spider Field để chuyển đổi sang json\n",
    "    \n",
    "    #Bắt đầu request\n",
    "    def start_requests(self):\n",
    "        start = 'https://www.iqair.com/vi/world-most-polluted-cities?sort=-rank&page=1&perPage=50' #Url bắt đầu\n",
    "\n",
    "        urls = [] #Danh sách url cần lấy dữ liệu\n",
    "        \n",
    "        for i in range(1, 131): #Có tổng cộng 130 url, lặp qua để thêm vào danh sách urls\n",
    "            url = start.replace('1', str(i))\n",
    "            urls.append(url)\n",
    "            \n",
    "        for url in urls: #Thực hiện request với từng url\n",
    "            yield scrapy.Request(url = url, callback = self.parse)\n",
    "    \n",
    "    #Lấy dữ liệu cần thiết\n",
    "    def parse(self, response):\n",
    "        #Tìm thẻ tbody chứa bảng 50 thành phố\n",
    "        res = response.css('tbody[role = \"rowgroup\"]') \n",
    "        \n",
    "        #Thêm từng thành phố vào list_rank, mỗi thành phố được định nghĩa trong thẻ tr\n",
    "        list_rank = np.array(res.css('tr')) \n",
    "        \n",
    "        #Với mỗi thành phố trích xuất dữ liệu cần thiết, những dữ liệu này đều nằm trong thẻ td\n",
    "        for i in list_rank:\n",
    "            city = i.css('td')\n",
    "            \n",
    "            self.data['Rank'] = city[0].css('td::text').get() #Hạng\n",
    "            self.data['City'] = city[1].css('div::text').get() #Tên thành phố\n",
    "            \n",
    "            self.data['Year_2021'] = city[2].css('span::text').get() #Chỉ số năm 2021\n",
    "            \n",
    "            self.data['Jan'] = city[3].css('span::text').get() #Chỉ số tháng 1\n",
    "            self.data['Feb'] = city[4].css('span::text').get() #Chỉ số tháng 2\n",
    "            self.data['Mar'] = city[5].css('span::text').get() #Chỉ số tháng 3\n",
    "            self.data['Apr'] = city[6].css('span::text').get() #Chỉ số tháng 4\n",
    "            self.data['May'] = city[7].css('span::text').get() #Chỉ số tháng 5\n",
    "            self.data['Jun'] = city[8].css('span::text').get() #Chỉ số tháng 6\n",
    "            self.data['Jul'] = city[9].css('span::text').get() #Chỉ số tháng 7\n",
    "            self.data['Aug'] = city[10].css('span::text').get() #Chỉ số tháng 8\n",
    "            self.data['Sep'] = city[11].css('span::text').get() #Chỉ số tháng 9\n",
    "            self.data['Oct'] = city[12].css('span::text').get() #Chỉ số tháng 10\n",
    "            self.data['Nov'] = city[13].css('span::text').get() #Chỉ số tháng 11\n",
    "            self.data['Dec'] = city[14].css('span::text').get() #Chỉ số tháng 12\n",
    "            \n",
    "            self.data['Year_2020'] = city[15].css('span::text').get() #Chỉ số năm 2020\n",
    "            self.data['Year_2019'] = city[16].css('span::text').get() #Chỉ số năm 2019\n",
    "            self.data['Year_2018'] = city[17].css('span::text').get() #Chỉ số năm 2018\n",
    "            self.data['Year_2017'] = city[18].css('span::text').get() #Chỉ số năm 2017\n",
    "                \n",
    "            yield self.data #Trả về spider Field data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7921c01",
   "metadata": {},
   "source": [
    "Vì thư viện scrapy không thể thực hiện lấy dữ liệu trực tiếp từ jupyter notebook, nên cần thực hiện tạo file collect_air_data.py trong đường dẫn **air_quality/air_qualiy/spiders/collect_air_data.py**. File collect_air_data.py sẽ chứa code của 2 cell code bên trên"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4681812",
   "metadata": {},
   "source": [
    "*Lưu ý*: Nếu file ipynb này thầy không chạy được thì thầy vui lòng  copy paste file ***collect_air_data.py*** mà chúng em đã nộp kèm theo vào thư mục theo hướng dẫn bên trên nếu chưa thực hiện. Chúng em xin cảm ơn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c13c71",
   "metadata": {},
   "source": [
    "Thực hiện chạy command bên dưới để crawl data về"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl air_datas -o crawldata/air_datas.json #Lấy dữ liệu và lưu vào file air_datas.json trong thư mục dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945b0a8",
   "metadata": {},
   "source": [
    "***Đọc dataframe từ file json***\\\n",
    "Với file json đã tạo khi thu thập dữ liệu, đọc vào df để kiểm tra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tao dataframe df_test để đọc air_data.json\n",
    "df_test = pd.read_json('crawldata/air_datas.json', encoding='utf-8-sig')\n",
    "\n",
    "df_test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a440aeac0c89e2af7569e0aa53b64434c4b69eb6285e2b0d174d9bca190d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
